# Spark Overview

Apache Spark is a unified analytics engine for large-scale data processing. It provides high-level APIs in Java, Scala, Python, and R, and an optimized engine that supports general execution graphs. It also supports a rich set of higher-level tools including Spark SQL for SQL and structured data processing, pandas API on Spark for pandas workloads, MLlib for machine learning, GraphX for graph processing, and Structured Streaming for incremental computation and stream processing.

<i>Reference: [Apache.org](https://spark.apache.org/docs/latest/)</i>

![alt text](https://avinash333.files.wordpress.com/2019/08/spark-architecture.png?w=960)

**Table of contents**
- [Spark Overview](#spark-overview)
- [Focus](#focus)
- [Library](#library)
- [Getting started](#getting-started)
- [References](#references)
- [Author](#author)

## Focus
Quickly introduction of the most common functions using Python API, with hands-on examples.

## Library
- Pandas
- Streamlit
- Requests  
- BeautifulSoup
- Time
- Math

## Getting started




## References 
- [Documentation](https://spark.apache.org/docs/latest/api/python/index.html)

## Author

Igor Traspadini

https://www.linkedin.com/in/xxxxxxxxxxx/
